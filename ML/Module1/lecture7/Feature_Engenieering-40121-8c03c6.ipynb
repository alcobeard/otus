{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.feature_selection import mutual_info_classif,chi2\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "plt.style.use('seaborn-colorblind')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [\n",
    "    'Pclass', 'Sex', 'Age', 'Fare', 'SibSp',\n",
    "    'Survived'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('/Users/muzalevskiy/Desktop/modules/titanic.csv', usecols=use_cols,sep='\\t')\n",
    "print(data.shape)\n",
    "data.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пропущенные значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing(data,output_path=None):    \n",
    "    result = pd.concat([data.isnull().sum(),data.isnull().mean()],axis=1)\n",
    "    result = result.rename(index=str,columns={0:'total missing',1:'proportion'})\n",
    "    if output_path is not None:\n",
    "        result.to_csv(output_path+'missing.csv')\n",
    "        print(output_path, 'missing.csv')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing(data,axis=0):\n",
    "    data_copy = data.copy(deep=True)\n",
    "    data_copy = data_copy.dropna(axis=axis,inplace=False)\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = drop_missing(data=data)\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление переменной оценки пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_var_denote_NA(data,NA_col=[]):\n",
    "    data_copy = data.copy(deep=True)\n",
    "    for i in NA_col:\n",
    "        if data_copy[i].isnull().sum()>0:\n",
    "            data_copy[i+'_is_NA'] = np.where(data_copy[i].isnull(),1,0)\n",
    "        else:\n",
    "            warn(\"Нет пропущенных значений\" % i)          \n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = add_var_denote_NA(data=data,NA_col=['Age'])\n",
    "print(data3.Age_is_NA.value_counts())\n",
    "data3.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение пропусков выборочным значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_NA_with_arbitrary(data,impute_value,NA_col=[]):  \n",
    "    data_copy = data.copy(deep=True)\n",
    "    for i in NA_col:\n",
    "        if data_copy[i].isnull().sum()>0:\n",
    "            data_copy[i+'_'+str(impute_value)] = data_copy[i].fillna(impute_value)\n",
    "        else:\n",
    "            warn(\"Нет пропущенных значений\" % i)\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = impute_NA_with_arbitrary(data=data,impute_value=-999,NA_col=['Age'])\n",
    "data4.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение пропущенных значений средним/медианой/модой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_NA_with_avg(data,strategy='mean',NA_col=[]):\n",
    "    data_copy = data.copy(deep=True)\n",
    "    for i in NA_col:\n",
    "        if data_copy[i].isnull().sum()>0:\n",
    "            if strategy=='mean':\n",
    "                data_copy[i+'_impute_mean'] = data_copy[i].fillna(data[i].mean())\n",
    "            elif strategy=='median':\n",
    "                data_copy[i+'_impute_median'] = data_copy[i].fillna(data[i].median())\n",
    "            elif strategy=='mode':\n",
    "                data_copy[i+'_impute_mode'] = data_copy[i].fillna(data[i].mode()[0])\n",
    "        else:\n",
    "            warn(\"Нет пропущенных значений\" % i)\n",
    "    return data_copy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.Age.median())\n",
    "data5 = impute_NA_with_avg(data=data,strategy='median',NA_col=['Age'])\n",
    "data5.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение пропусков значением из \"хвоста\" распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_NA_with_end_of_distribution(data,NA_col=[]):\n",
    "    data_copy = data.copy(deep=True)\n",
    "    for i in NA_col:\n",
    "        if data_copy[i].isnull().sum()>0:\n",
    "            data_copy[i+'_impute_end_of_distri'] = data_copy[i].fillna(data[i].mean()+3*data[i].std())\n",
    "        else:\n",
    "            warn(\"Нет пропущенных значений\" % i)\n",
    "    return data_copy     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6 = impute_NA_with_end_of_distribution(data=data,NA_col=['Age'])\n",
    "data6.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение пропусков случайными значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_NA_with_random(data,NA_col=[],random_state=0):\n",
    "    data_copy = data.copy(deep=True)\n",
    "    for i in NA_col:\n",
    "        if data_copy[i].isnull().sum()>0:\n",
    "            data_copy[i+'_random'] = data_copy[i]\n",
    "            random_sample = data_copy[i].dropna().sample(data_copy[i].isnull().sum(), random_state=random_state)\n",
    "            random_sample.index = data_copy[data_copy[i].isnull()].index\n",
    "            data_copy.loc[data_copy[i].isnull(), str(i)+'_random'] = random_sample\n",
    "        else:\n",
    "            warn(\"Нет пропущенных значений\" % i)\n",
    "    return data_copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7 = impute_NA_with_random(data=data,NA_col=['Age'])\n",
    "data7.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детекция с помощью выборочных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detect_arbitrary(data,col,upper_fence,lower_fence):\n",
    "    para = (upper_fence, lower_fence)\n",
    "    tmp = pd.concat([data[col]>upper_fence,data[col]<lower_fence],axis=1)\n",
    "    outlier_index = tmp.any(axis=1)\n",
    "    print('Количество выбросов в данных:',outlier_index.value_counts()[1])\n",
    "    print('Доля выбросов:',outlier_index.value_counts()[1]/len(outlier_index))    \n",
    "    return outlier_index, para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index,para = outlier_detect_arbitrary(data=data,col='Fare',upper_fence=100,lower_fence=5)\n",
    "print('Верхняя граница:',para[0],'\\nНижняя граница:',para[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[index,'Fare'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интерквартильное расстояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detect_IQR(data,col,threshold=3):    \n",
    "    IQR = data[col].quantile(0.75) - data[col].quantile(0.25)\n",
    "    Lower_fence = data[col].quantile(0.25) - (IQR * threshold)\n",
    "    Upper_fence = data[col].quantile(0.75) + (IQR * threshold)\n",
    "    para = (Upper_fence, Lower_fence)\n",
    "    tmp = pd.concat([data[col]>Upper_fence,data[col]<Lower_fence],axis=1)\n",
    "    outlier_index = tmp.any(axis=1)\n",
    "    print('Количество выбросов в данных:',outlier_index.value_counts()[1])\n",
    "    print('Доля выбросов:',outlier_index.value_counts()[1]/len(outlier_index))\n",
    "    return outlier_index, para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index,para = outlier_detect_IQR(data=data,col='Fare',threshold=5)\n",
    "print('Верхняя граница:',para[0],'\\nНижняя граница:',para[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[index,'Fare'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среднее-среднеквадратичное отклонение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detect_mean_std(data,col,threshold=3):\n",
    "    Upper_fence = data[col].mean() + threshold * data[col].std()\n",
    "    Lower_fence = data[col].mean() - threshold * data[col].std()   \n",
    "    para = (Upper_fence, Lower_fence)   \n",
    "    tmp = pd.concat([data[col]>Upper_fence,data[col]<Lower_fence],axis=1)\n",
    "    outlier_index = tmp.any(axis=1)\n",
    "    print('Количество выбросов в данных:',outlier_index.value_counts()[1])\n",
    "    print('Доля выбросов:',outlier_index.value_counts()[1]/len(outlier_index))\n",
    "    return outlier_index, para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index,para = outlier_detect_mean_std(data=data,col='Fare',threshold=3)\n",
    "print('Верхняя граница:',para[0],'\\nНижняя граница:',para[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[index,'Fare'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Медианы абсолютного отклонения (MAD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detect_MAD(data,col,threshold=3.5):\n",
    "    median = data[col].median()\n",
    "    median_absolute_deviation = np.median([np.abs(y - median) for y in data[col]])\n",
    "    modified_z_scores = pd.Series([0.6745 * (y - median) / median_absolute_deviation for y in data[col]])\n",
    "    outlier_index = np.abs(modified_z_scores) > threshold\n",
    "    print('Количество выбросов в данных:',outlier_index.value_counts()[1])\n",
    "    print('Доля выбросов:',outlier_index.value_counts()[1]/len(outlier_index))\n",
    "    return outlier_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = outlier_detect_MAD(data=data,col='Fare',threshold=3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замена выброса выборочным значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_outlier_with_arbitrary(data,outlier_index,value,col=[]):\n",
    "    data_copy = data.copy(deep=True)\n",
    "    for i in col:\n",
    "        data_copy.loc[outlier_index,i] = value\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = impute_outlier_with_arbitrary(data=data,outlier_index=index,\n",
    "                                         value=-999,col=['Fare'])\n",
    "data2[25:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виндзоризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{92, 19, 101, 58, 1053, 91, 26, 78, 10, 13, −40, 101, 86, 85, 15, 89, 89, 28, −5, 41}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{92, 19, 101, 58, 101, 91, 26, 78, 10, 13, −5, 101, 86, 85, 15, 89, 89, 28, −5, 41} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windsorization(data,col,para,strategy='both'):\n",
    "    data_copy = data.copy(deep=True)  \n",
    "    if strategy == 'both':\n",
    "        data_copy.loc[data_copy[col]>para[0],col] = para[0]\n",
    "        data_copy.loc[data_copy[col]<para[1],col] = para[1]\n",
    "    elif strategy == 'top':\n",
    "        data_copy.loc[data_copy[col]>para[0],col] = para[0]\n",
    "    elif strategy == 'bottom':\n",
    "        data_copy.loc[data_copy[col]<para[1],col] = para[1]  \n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = windsorization(data=data,col='Fare',para=para,strategy='both')\n",
    "data3[25:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outlier(data,outlier_index):\n",
    "    data_copy = data[~outlier_index]\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = drop_outlier(data=data,outlier_index=index)\n",
    "print(data4.Fare.max())\n",
    "print(data4.Fare.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замена выбросов средним/медианой/модой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_outlier_with_avg(data,col,outlier_index,strategy='mean'):\n",
    "    data_copy = data.copy(deep=True)\n",
    "    if strategy=='mean':\n",
    "        data_copy.loc[outlier_index,col] = data_copy[col].mean()\n",
    "    elif strategy=='median':\n",
    "        data_copy.loc[outlier_index,col] = data_copy[col].median()\n",
    "    elif strategy=='mode':\n",
    "        data_copy.loc[outlier_index,col] = data_copy[col].mode()[0]           \n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = impute_outlier_with_avg(data=data,col='Fare',\n",
    "                                   outlier_index=index,strategy='mean')\n",
    "data5[25:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Шкалирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, data.Survived, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler().fit(X_train[['Fare']])\n",
    "X_train_copy = X_train.copy(deep=True)\n",
    "X_train_copy['Fare_zscore'] = ss.transform(X_train_copy[['Fare']])\n",
    "print(X_train_copy.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_copy['Fare_zscore'].mean())\n",
    "print(X_train_copy['Fare_zscore'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мин-Макс шкалирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler().fit(X_train[['Fare']])\n",
    "X_train_copy = X_train.copy(deep=True)\n",
    "X_train_copy['Fare_minmax'] = mms.transform(X_train_copy[['Fare']])\n",
    "print(X_train_copy.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_copy['Fare_minmax'].max())\n",
    "print(X_train_copy['Fare_minmax'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Робустное шкалирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler().fit(X_train[['Fare']])\n",
    "X_train_copy = X_train.copy(deep=True)\n",
    "X_train_copy['Fare_robust'] = rs.transform(X_train_copy[['Fare']])\n",
    "print(X_train_copy.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Энкодинг переменных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.get_dummies(data,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Энкодинг значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = ce.OrdinalEncoder(cols=['Sex']).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = ord_enc.transform(data)\n",
    "print(data4.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таргет энкодинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_enc = ce.TargetEncoder(cols=['Sex']).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = target_enc.transform(data)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOE энкодинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_enc = ce.WOEEncoder(cols=['Sex']).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = woe_enc.transform(data)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "data = pd.DataFrame(np.c_[data['data'], data['target']],\n",
    "                  columns= np.append(data['feature_names'], ['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(labels=['target'], axis=1), \n",
    "                                                    data.target, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Константные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_feature_detect(data,threshold=0.98):    \n",
    "    data_copy = data.copy(deep=True)\n",
    "    quasi_constant_feature = []\n",
    "    for feature in data_copy.columns:\n",
    "        predominant = (data_copy[feature].value_counts() / np.float(\n",
    "                      len(data_copy))).sort_values(ascending=False).values[0]\n",
    "        if predominant >= threshold:\n",
    "            quasi_constant_feature.append(feature)\n",
    "    print(len(quasi_constant_feature),'константные переменные')    \n",
    "    return quasi_constant_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_constant_feature = constant_feature_detect(data=X_train,threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['dummy'] = np.floor(X_train['worst smoothness']*10)\n",
    "X_train.dummy.value_counts() / np.float(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_constant_feature = constant_feature_detect(data=X_train,threshold=0.9)\n",
    "quasi_constant_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(labels=quasi_constant_feature,axis=1,inplace=True)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корреляционная фильтрация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_feature_detect(data,threshold=0.8):\n",
    "    \n",
    "    corrmat = data.corr()\n",
    "    corrmat = corrmat.abs().unstack() \n",
    "    corrmat = corrmat.sort_values(ascending=False)\n",
    "    corrmat = corrmat[corrmat >= threshold]\n",
    "    corrmat = corrmat[corrmat < 1] \n",
    "    corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "    corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "   \n",
    "    grouped_feature_ls = []\n",
    "    correlated_groups = []\n",
    "    \n",
    "    for feature in corrmat.feature1.unique():\n",
    "        if feature not in grouped_feature_ls:\n",
    "    \n",
    "            correlated_block = corrmat[corrmat.feature1 == feature]\n",
    "            grouped_feature_ls = grouped_feature_ls + list(\n",
    "                correlated_block.feature2.unique()) + [feature]\n",
    "    \n",
    "            correlated_groups.append(correlated_block)\n",
    "    return correlated_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = corr_feature_detect(data=X_train,threshold=0.9)\n",
    "for i in corr:\n",
    "    print(i,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взаимная информация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info(X,y,select_k=10):\n",
    "\n",
    "    if select_k >= 1:\n",
    "        sel_ = SelectKBest(mutual_info_classif, k=select_k).fit(X,y)\n",
    "        col = X.columns[sel_.get_support()]\n",
    "        \n",
    "    elif 0 < select_k < 1:\n",
    "        sel_ = SelectPercentile(mutual_info_classif, percentile=select_k*100).fit(X,y)\n",
    "        col = X.columns[sel_.get_support()]   \n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"select_k должно быть положительным значением\")\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info(X=X_train,y=y_train,select_k=3)\n",
    "print(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info(X=X_train,y=y_train,select_k=0.2)\n",
    "print(mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хи-квадрат тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_test(X,y,select_k=10):\n",
    "\n",
    "    if select_k >= 1:\n",
    "        sel_ = SelectKBest(chi2, k=select_k).fit(X,y)\n",
    "        col = X.columns[sel_.get_support()]\n",
    "    elif 0 < select_k < 1:\n",
    "        sel_ = SelectPercentile(chi2, percentile=select_k*100).fit(X,y)\n",
    "        col = X.columns[sel_.get_support()]   \n",
    "    else:\n",
    "        raise ValueError(\"select_k должно быть положительным значением\")  \n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = chi_square_test(X=X_train,y=y_train,select_k=3)\n",
    "print(chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = chi_square_test(X=X_train,y=y_train,select_k=0.2)\n",
    "print(chi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одномерный ROC-AUC или MSE анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_roc_auc(X_train,y_train,X_test,y_test,threshold):\n",
    "\n",
    "    roc_values = []\n",
    "    for feature in X_train.columns:\n",
    "        clf = DecisionTreeClassifier()\n",
    "        clf.fit(X_train[feature].to_frame(), y_train)\n",
    "        y_scored = clf.predict_proba(X_test[feature].to_frame())\n",
    "        roc_values.append(roc_auc_score(y_test, y_scored[:, 1]))\n",
    "    roc_values = pd.Series(roc_values)\n",
    "    roc_values.index = X_train.columns\n",
    "    print(roc_values.sort_values(ascending=False))\n",
    "    print(len(roc_values[roc_values > threshold]), len(X_train.columns))\n",
    "    keep_col = roc_values[roc_values > threshold]\n",
    "    return keep_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_roc_auc = univariate_roc_auc(X_train=X_train,y_train=y_train,\n",
    "                                   X_test=X_test,y_test=y_test,threshold=0.8)\n",
    "print(uni_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_mse(X_train,y_train,X_test,y_test,threshold):\n",
    "\n",
    "    mse_values = []\n",
    "    for feature in X_train.columns:\n",
    "        clf = DecisionTreeRegressor()\n",
    "        clf.fit(X_train[feature].to_frame(), y_train)\n",
    "        y_scored = clf.predict(X_test[feature].to_frame())\n",
    "        mse_values.append(mean_squared_error(y_test, y_scored))\n",
    "    mse_values = pd.Series(mse_values)\n",
    "    mse_values.index = X_train.columns\n",
    "    print(mse_values.sort_values(ascending=False))\n",
    "    print(len(mse_values[mse_values > threshold]), len(X_train.columns))\n",
    "    keep_col = mse_values[mse_values > threshold]\n",
    "    return keep_col   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_mse = univariate_mse(X_train=X_train,y_train=y_train,\n",
    "                            X_test=X_test,y_test=y_test,threshold=0.4)\n",
    "print(uni_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling/undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = CondensedNearestNeighbour(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = cn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
